{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SER_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIvJTC0EsLjnV/08NYIVmS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iasonaspg/ser-repo/blob/main/SER_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YyhdsAjCDnZ",
        "outputId": "b38fdc89-ac16-454c-c192-d88edf885024"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FnGuGZJDOb0",
        "outputId": "175c1152-8909-4011-9e06-91b394c38ac7"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Emotions/')\n",
        "!ls "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "anger  disgust\tfear  happiness  sadness\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzYtHFdnDwWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e504377-f135-4692-84cd-63b3fff6e13a"
      },
      "source": [
        "!python -m pip install -U pip\n",
        "!pip uninstall librosa\n",
        "!pip install librosa\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio, display"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/11/2dc62c5263d9eb322f2f028f7b56cd9d096bb8988fcf82d65fa2e4057afe/pip-20.3.1-py2.py3-none-any.whl (1.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 12.7MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 18.4MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 14.3MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 11.5MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 8.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 8.5MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 9.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 9.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 9.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 9.3MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133kB 9.3MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 9.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153kB 9.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163kB 9.3MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174kB 9.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 184kB 9.3MB/s eta 0:00:01\r\u001b[K     |████                            | 194kB 9.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 204kB 9.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 215kB 9.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 225kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 245kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 256kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 266kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 276kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 296kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 307kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 317kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 327kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 337kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 348kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 358kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 368kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 378kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 389kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 399kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 409kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 419kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 430kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 440kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 450kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 460kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 481kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 491kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 501kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 512kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 522kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 532kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 542kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 552kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 563kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 573kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 583kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 593kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 604kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 614kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 624kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 634kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 645kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 655kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 665kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 675kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 686kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 696kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 706kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 716kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 727kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 737kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 747kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 757kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 768kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 778kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 788kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 798kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 808kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 819kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 829kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 839kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 849kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 860kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 870kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 880kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 890kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 901kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 911kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 921kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 931kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 942kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 952kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 962kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 972kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 983kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 993kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.0MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.0MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.0MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.0MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.4MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.4MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.4MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.4MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.4MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.4MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.5MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.5MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.5MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.5MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.5MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 9.3MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.3.1\n",
            "Found existing installation: librosa 0.6.3\n",
            "Uninstalling librosa-0.6.3:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/librosa-0.6.3.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/librosa/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled librosa-0.6.3\n",
            "Collecting librosa\n",
            "  Downloading librosa-0.8.0.tar.gz (183 kB)\n",
            "\u001b[K     |████████████████████████████████| 183 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.17.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.48.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa) (50.3.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.18.5)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa) (0.31.0)\n",
            "Collecting pooch>=1.0\n",
            "  Downloading pooch-1.3.0-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 355 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa) (20.4)\n",
            "Collecting appdirs\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->pooch>=1.0->librosa) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->pooch>=1.0->librosa) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->pooch>=1.0->librosa) (1.15.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.48.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.18.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.17.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.18.5)\n",
            "Collecting soundfile>=0.9.0\n",
            "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa) (1.14.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.20)\n",
            "Building wheels for collected packages: librosa\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201376 sha256=b45b081c0f6f2a6dbd8753755dc8e009c9465b542b26d08551a9ab48b03c6f4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/2c/ce/86e49d4769aceba728421c24c0d726054bf4ca01175ff42bdd\n",
            "Successfully built librosa\n",
            "Installing collected packages: appdirs, soundfile, pooch, librosa\n",
            "Successfully installed appdirs-1.4.4 librosa-0.8.0 pooch-1.3.0 soundfile-0.10.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U9Y8_lvNdH9",
        "outputId": "5615fa39-21b8-43a7-c382-eec888a5826d"
      },
      "source": [
        "print(librosa.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpM1p_TvIzm-"
      },
      "source": [
        "# load audio file\n",
        "from pathlib import Path\n",
        "fs = 22050\n",
        "n_fft, hop = 1024, 256\n",
        "\n",
        "# Fucntions require you to be in the root data directory\n",
        "def get_train_wav_dir(dir_name,fs=44100):\n",
        "  return [ librosa.load(p,fs)[0] for p in Path().glob('./' + dir_name + '/train' + '/*.wav') ]\n",
        "\n",
        "def get_test_wav_dir(dir_name,fs=44100):\n",
        "  return [ librosa.load(p,fs)[0] for p in Path().glob('./' + dir_name + '/test' + '/*.wav') ]\n",
        "\n",
        "\n",
        "\n",
        "emotions = [\"sadness\",\"happiness\",\"anger\",\"fear\",\"disgust\"]\n",
        "\n",
        "# list of len(emotions) that contains lists of numpy arrays. Each numpy array belongs to a single wav file\n",
        "train_wav = []\n",
        "test_wav = []\n",
        "for emotion in emotions:\n",
        "  train_wav.append(get_train_wav_dir(emotion,fs))\n",
        "  test_wav.append(get_test_wav_dir(emotion,fs))\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVbiwoMCBreL",
        "outputId": "6bdd1e31-d3b0-4d92-86f9-549472ed8d2b"
      },
      "source": [
        "from numpy import genfromtxt\n",
        "\n",
        "os.chdir('/content/drive/My Drive/Br_CSV/')\n",
        "\n",
        "\n",
        "br_train = []\n",
        "br_test = []\n",
        "for emotion in emotions:\n",
        "  filename = 'br_' + emotion + '_train.csv'\n",
        "  temp = genfromtxt(filename,delimiter=',')\n",
        "  np.nan_to_num(temp,copy=False)\n",
        "  br_train.append(temp)\n",
        "  filename = 'br_' + emotion + '_test.csv'\n",
        "  temp = genfromtxt(filename,delimiter=',')\n",
        "  np.nan_to_num(temp,copy=False)\n",
        "  br_test.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "print(br_train[0].shape)\n",
        "print(br_train[1].shape)\n",
        "print(br_train[2].shape)\n",
        "print(br_train[3].shape)\n",
        "print(br_train[4].shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 32013)\n",
            "(2, 28208)\n",
            "(2, 25665)\n",
            "(2, 27131)\n",
            "(2, 34553)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUsxOLnALgJ4"
      },
      "source": [
        "for i in range(len(train_wav)):\n",
        "  for j in range(len(train_wav[i])):\n",
        "    train_wav[i][j], _ = librosa.effects.trim(train_wav[i][j],top_db=15,frame_length=128,hop_length=32)\n",
        "    #display(Audio(i, rate=fs))\n",
        "    #plt.plot(i)\n",
        "    #plt.show()\n",
        "    #plt.plot(i_t)\n",
        "    #plt.show()\n",
        "\n",
        "for i in range(len(test_wav)):\n",
        "  for j in range(len(test_wav[i])):\n",
        "    test_wav[i][j], _ = librosa.effects.trim(test_wav[i][j],top_db=15,frame_length=128,hop_length=32)\n",
        "\n",
        "# print(index)\n",
        "plt.plot(train_wav[0][0])\n",
        "plt.plot(train_wav[2][7])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Uld-drDRpa"
      },
      "source": [
        "display(Audio(train_wav[0][0], rate=fs))\n",
        "print(train_wav[1][0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2GE7RSiQLXd",
        "outputId": "edb363ab-18ea-48cc-fe17-a26097612e4a"
      },
      "source": [
        "from librosa.feature import spectral\n",
        "\n",
        "# Gets a list of wav signals and returns a numpy array of features x nFrames_total and a list of len(input) containing the nFrames per signal\n",
        "def extract_features(wav):\n",
        "  spectral_centroid = spectral.spectral_centroid(wav[0], sr=fs, n_fft=n_fft, hop_length=hop, center=False)\n",
        "  spectral_rolloff = spectral.spectral_rolloff(wav[0], sr=fs, n_fft=n_fft, hop_length=hop,roll_percent=0.30, center=False)\n",
        "  zero_crossing_rate = spectral.zero_crossing_rate(wav[0], frame_length=n_fft, hop_length=hop, center=False)\n",
        "  mfcc = librosa.feature.mfcc(wav[0], sr=fs, n_fft=n_fft, hop_length=hop, n_mfcc=7, center=False)\n",
        "  desired_mfcc = np.concatenate((mfcc[1:2,:],mfcc[4:5,:],mfcc[6:7,:]),axis=0)\n",
        "  mfcc_delta = librosa.feature.delta(desired_mfcc, order=1, mode='nearest')\n",
        "  mfcc_delta2 = librosa.feature.delta(desired_mfcc, order=2, mode='nearest')\n",
        "  feature_vector = np.concatenate((spectral_centroid,spectral_rolloff,zero_crossing_rate,desired_mfcc,mfcc_delta,mfcc_delta2),axis=0)\n",
        "  nFrames = [0 for i in range(len(wav))]\n",
        "  nFrames[0] = spectral_centroid.shape[1]\n",
        "  for i in range(1,len(wav)):\n",
        "    cols = wav[i].shape[0]\n",
        "    spectral_centroid = spectral.spectral_centroid(wav[i], sr=fs, n_fft=n_fft, hop_length=hop, center=False)\n",
        "    spectral_rolloff = spectral.spectral_rolloff(wav[i], sr=fs, n_fft=n_fft, hop_length=hop,roll_percent=0.30, center=False)\n",
        "    zero_crossing_rate = spectral.zero_crossing_rate(wav[i], frame_length=n_fft, hop_length=hop, center=False)\n",
        "    mfcc = librosa.feature.mfcc(wav[i], sr=fs, n_fft=n_fft, hop_length=hop, n_mfcc=7, center=False)\n",
        "    desired_mfcc = np.concatenate((mfcc[1:2,:],mfcc[4:5,:],mfcc[6:7,:]),axis=0)\n",
        "    mfcc_delta = librosa.feature.delta(desired_mfcc, order=1, mode='nearest')\n",
        "    mfcc_delta2 = librosa.feature.delta(desired_mfcc, order=2, mode='nearest')\n",
        "    feature_vector1 = np.concatenate((spectral_centroid,spectral_rolloff,zero_crossing_rate,desired_mfcc,mfcc_delta,mfcc_delta2),axis=0)\n",
        "    feature_vector = np.concatenate((feature_vector,feature_vector1),axis=1)\n",
        "    nFrames[i] = spectral_centroid.shape[1]\n",
        "  return feature_vector, nFrames\n",
        "\n",
        "\n",
        "test_nframes = []\n",
        "train_nframes = []\n",
        "feature_train_vector, _ = extract_features(train_wav[0])\n",
        "label_vec = [0 for i in range(feature_train_vector.shape[1])]\n",
        "feature_train_vector = np.concatenate((feature_train_vector,br_train[0],np.array([label_vec])),axis=0)\n",
        "\n",
        "feature_test_vector, test_nframe = extract_features(test_wav[0])\n",
        "label_vec = [0 for i in range(feature_test_vector.shape[1])]\n",
        "feature_test_vector = np.concatenate((feature_test_vector,br_test[0],np.array([label_vec])),axis=0)\n",
        "test_nframes.append(test_nframe)\n",
        "for i in range(1,len(train_wav)):\n",
        "  train_feat_vec, train_nframe = extract_features(train_wav[i])\n",
        "  train_nframes.append(train_nframe)\n",
        "  label_vec = [i for j in range(train_feat_vec.shape[1])]\n",
        "  train_feat_vec = np.concatenate((train_feat_vec,br_train[i],np.array([label_vec])),axis=0)\n",
        "  feature_train_vector = np.concatenate((feature_train_vector,train_feat_vec),axis=1)\n",
        "\n",
        "  \n",
        "  test_feat_vec, test_nframe = extract_features(test_wav[i])\n",
        "  test_nframes.append(test_nframe)\n",
        "  label_vec = [i for j in range(test_feat_vec.shape[1])]\n",
        "  test_feat_vec = np.concatenate((test_feat_vec,br_test[i],np.array([label_vec])),axis=0)\n",
        "  feature_test_vector = np.concatenate((feature_test_vector,test_feat_vec),axis=1)\n",
        "\n",
        "\n",
        "print(feature_test_vector.shape)\n",
        "#print(happy_train_feat_vec.shape)\n",
        "print('=')\n",
        "print(feature_train_vector.shape)\n",
        "#print(feature_vector[:,0:2])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15, 25205)\n",
            "=\n",
            "(15, 147570)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYN0jeGs7_46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e483d258-754a-44ec-a982-412e6405cb01"
      },
      "source": [
        "print(feature_train_vector[:,131130])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 5.94429251e+03  4.90957031e+03  5.41992188e-01 -1.18576645e+02\n",
            " -1.97425385e+01 -9.49008369e+00 -1.35814381e+01 -4.55100155e+00\n",
            " -6.36391401e-01  7.51859760e+00 -5.49362935e-02  1.70328379e-01\n",
            "  9.94840000e-01  9.90660000e-01  4.00000000e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "9tITojZozbET",
        "outputId": "c4719528-bd63-4624-ec2b-f3b3f2a42934"
      },
      "source": [
        "import pandas as pd\n",
        "index = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\"]\n",
        "feat_train = feature_train_vector[0:14,:]\n",
        "\n",
        "pd_feat_train = pd.DataFrame(feat_train.T)\n",
        "pd_feat_train.describe()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2466.849859</td>\n",
              "      <td>1094.105888</td>\n",
              "      <td>0.135340</td>\n",
              "      <td>69.904337</td>\n",
              "      <td>-5.913831</td>\n",
              "      <td>-12.793342</td>\n",
              "      <td>-0.000116</td>\n",
              "      <td>0.023334</td>\n",
              "      <td>-0.012004</td>\n",
              "      <td>0.005912</td>\n",
              "      <td>-0.002650</td>\n",
              "      <td>0.001906</td>\n",
              "      <td>0.840143</td>\n",
              "      <td>0.667034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1568.838165</td>\n",
              "      <td>1447.979581</td>\n",
              "      <td>0.147026</td>\n",
              "      <td>63.951290</td>\n",
              "      <td>27.270888</td>\n",
              "      <td>20.128150</td>\n",
              "      <td>10.570079</td>\n",
              "      <td>3.965490</td>\n",
              "      <td>2.929460</td>\n",
              "      <td>5.122999</td>\n",
              "      <td>2.014720</td>\n",
              "      <td>1.662102</td>\n",
              "      <td>0.199235</td>\n",
              "      <td>0.237168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>26.587444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-235.525085</td>\n",
              "      <td>-149.226013</td>\n",
              "      <td>-100.508789</td>\n",
              "      <td>-45.974712</td>\n",
              "      <td>-20.612913</td>\n",
              "      <td>-14.117944</td>\n",
              "      <td>-25.144709</td>\n",
              "      <td>-10.745960</td>\n",
              "      <td>-7.945780</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1408.982815</td>\n",
              "      <td>322.998047</td>\n",
              "      <td>0.045898</td>\n",
              "      <td>37.315625</td>\n",
              "      <td>-22.989209</td>\n",
              "      <td>-25.982828</td>\n",
              "      <td>-5.185256</td>\n",
              "      <td>-2.336780</td>\n",
              "      <td>-1.812250</td>\n",
              "      <td>-2.983755</td>\n",
              "      <td>-1.236926</td>\n",
              "      <td>-1.023916</td>\n",
              "      <td>0.775510</td>\n",
              "      <td>0.512320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1956.965492</td>\n",
              "      <td>495.263672</td>\n",
              "      <td>0.076172</td>\n",
              "      <td>79.371826</td>\n",
              "      <td>-5.786995</td>\n",
              "      <td>-11.890460</td>\n",
              "      <td>-0.186710</td>\n",
              "      <td>0.075184</td>\n",
              "      <td>0.035244</td>\n",
              "      <td>-0.151757</td>\n",
              "      <td>-0.001493</td>\n",
              "      <td>-0.002288</td>\n",
              "      <td>0.907740</td>\n",
              "      <td>0.697565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2956.028462</td>\n",
              "      <td>968.994141</td>\n",
              "      <td>0.150391</td>\n",
              "      <td>113.570728</td>\n",
              "      <td>11.082223</td>\n",
              "      <td>1.120397</td>\n",
              "      <td>5.244794</td>\n",
              "      <td>2.453499</td>\n",
              "      <td>1.856264</td>\n",
              "      <td>2.622996</td>\n",
              "      <td>1.208461</td>\n",
              "      <td>1.027122</td>\n",
              "      <td>0.980080</td>\n",
              "      <td>0.864457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>8398.838795</td>\n",
              "      <td>8161.083984</td>\n",
              "      <td>0.805664</td>\n",
              "      <td>251.672791</td>\n",
              "      <td>115.711357</td>\n",
              "      <td>81.680939</td>\n",
              "      <td>53.939419</td>\n",
              "      <td>19.865591</td>\n",
              "      <td>13.983083</td>\n",
              "      <td>26.298500</td>\n",
              "      <td>10.816760</td>\n",
              "      <td>9.126064</td>\n",
              "      <td>0.999950</td>\n",
              "      <td>0.999920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0              1   ...             12             13\n",
              "count  147570.000000  147570.000000  ...  147570.000000  147570.000000\n",
              "mean     2466.849859    1094.105888  ...       0.840143       0.667034\n",
              "std      1568.838165    1447.979581  ...       0.199235       0.237168\n",
              "min        26.587444       0.000000  ...       0.000000       0.000000\n",
              "25%      1408.982815     322.998047  ...       0.775510       0.512320\n",
              "50%      1956.965492     495.263672  ...       0.907740       0.697565\n",
              "75%      2956.028462     968.994141  ...       0.980080       0.864457\n",
              "max      8398.838795    8161.083984  ...       0.999950       0.999920\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w4O0CI8XZVe"
      },
      "source": [
        "a = np.asarray(feature_train_vector)\n",
        "np.savetxt(\"feature_train_vector.csv\", a, delimiter=\",\")\n",
        "\n",
        "a = np.asarray(feature_test_vector)\n",
        "np.savetxt(\"feature_test_vector.csv\", a, delimiter=\",\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WVfVVNzxUG3"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "os.chdir('/content/drive/My Drive/Br_CSV/')\n",
        "\n",
        "feature_train_vector = np.genfromtxt(\"feature_train_vector.csv\", delimiter=\",\")\n",
        "feature_test_vector = np.genfromtxt(\"feature_test_vector.csv\", delimiter=\",\")\n",
        "print(feature_train_vector.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVl-zEedS1Fn"
      },
      "source": [
        "import sklearn\n",
        "from sklearn import decomposition\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train = feature_train_vector[0:14,:].T\n",
        "Y_train = feature_train_vector[14,:].T\n",
        "\n",
        "X_test = feature_test_vector[0:14,:].T\n",
        "Y_test = feature_test_vector[14,:].T\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "scaler.fit(X_test)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "pca = sklearn.decomposition.PCA(n_components=14)\n",
        "pca_train = pca.fit_transform(X_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# fig, axes = plt.subplots(1,2)\n",
        "# axes[0].scatter(feature_train_vector[3:4,:].T, feature_train_vector[12:13,:].T, c=feature_train_vector[14,].T)\n",
        "# axes[0].set_xlabel('x1')\n",
        "# axes[0].set_ylabel('x2')\n",
        "# axes[0].set_title('Before PCA')\n",
        "# axes[1].scatter(pca_train[3:4,:], pca_train[12:13,:], c=feature_train_vector[14,].T)\n",
        "# axes[1].set_xlabel('PC1')\n",
        "# axes[1].set_ylabel('PC2')\n",
        "# axes[1].set_title('After PCA')\n",
        "# plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1NLMr25kajp"
      },
      "source": [
        "print(pca.explained_variance_ratio_,\"\\n\")\n",
        "#print(pca.explained_variance_)\n",
        "print(abs( pca.components_ )[0],\"\\n\")\n",
        "print(abs( pca.components_ )[1],\"\\n\")\n",
        "print(abs( pca.components_ )[2],\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKCKi0wUdfVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3501d58-9905-4a33-f8ba-b9216cb57fb4"
      },
      "source": [
        "from joblib import dump, load\n",
        "from sklearn import svm\n",
        "import time\n",
        "\n",
        "\n",
        "X_train = feature_train_vector[0:14,:].T\n",
        "Y_train = feature_train_vector[14,:].T\n",
        "Y_test = feature_test_vector[14,:].T\n",
        "X_test = feature_test_vector[0:14,:].T\n",
        "\n",
        "clf = svm.SVC(C=1.0)\n",
        "str = time.time()\n",
        "clf.fit(X_train, Y_train)\n",
        "print(time.time()-str)\n",
        "\n",
        "dump(clf, './svm_raw14_c1.joblib') "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1830.6374039649963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./svm_raw14_c1.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dyXIdmmRDBT"
      },
      "source": [
        "from joblib import dump, load\n",
        "from sklearn import svm\n",
        "\n",
        "clf = load('./svm_model.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d3inecO188_"
      },
      "source": [
        "import statistics \n",
        "from statistics import mode,mean\n",
        "\n",
        "def get_label(y):\n",
        "  return mode(y)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPgNPjzFp8jw"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"CPU: \\n\")\n",
        "\n",
        "accuracy_list = []\n",
        "\n",
        "\n",
        "Y_test = feature_test_vector[14,:].T\n",
        "X_test = feature_test_vector[0:14,:].T\n",
        "\n",
        "i = 0\n",
        "for k in test_nframes:\n",
        "  for j in k:\n",
        "    pred = clf.predict(X_test[i:i+j,:])\n",
        "    try:\n",
        "      val = mode(pred)\n",
        "    except:\n",
        "      val = round(mean(pred))\n",
        "    acc = accuracy_score(Y_test[i:i+j,],pred,True)\n",
        "    accuracy_list.append(acc)\n",
        "    print(acc)\n",
        "    i = i + j\n",
        "\n",
        "print(\"Mean CPU accuracy: \", np.mean(accuracy_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8AYszUgfAq1"
      },
      "source": [
        "pred = clf.predict(X_test)\n",
        "print(metrics.classification_report(Y_test, pred, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vbQmH5PR85Q",
        "outputId": "8a32b4e2-3afa-4f64-d859-155fd41755b8"
      },
      "source": [
        "from sklearn import metrics\n",
        "#from sklearn.metrics import accuracy_score\n",
        "\n",
        "Y_test = feature_test_vector[14,:].T\n",
        "X_test = feature_test_vector[0:14,:].T\n",
        "\n",
        "print(\"CPU: \\n\")\n",
        "\n",
        "accuracy_list = []\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "i = 0\n",
        "label = 0\n",
        "for k in test_nframes:\n",
        "  for j in k:\n",
        "    pred = clf.predict(X_test[i:i+j,:])\n",
        "    try:\n",
        "      val = mode(pred)\n",
        "    except:\n",
        "      #print(pred)\n",
        "      val = round(mean(pred))\n",
        "    y_pred.append(val)\n",
        "    y_true.append(label)\n",
        "    i = i + j\n",
        "  label = label + 1\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(metrics.confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# Print the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_true, y_pred, digits=3))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU: \n",
            "\n",
            "[[15  0  0  0  3]\n",
            " [ 4  0  0  1 12]\n",
            " [ 4  0  3  0 11]\n",
            " [ 7  0  1  0  9]\n",
            " [ 2  0  0  0 16]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.469     0.833     0.600        18\n",
            "           1      0.000     0.000     0.000        17\n",
            "           2      0.750     0.167     0.273        18\n",
            "           3      0.000     0.000     0.000        17\n",
            "           4      0.314     0.889     0.464        18\n",
            "\n",
            "    accuracy                          0.386        88\n",
            "   macro avg      0.306     0.378     0.267        88\n",
            "weighted avg      0.313     0.386     0.273        88\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqXa_DqyF2OQ",
        "outputId": "4d88a289-300c-422e-b7fd-eb16724d9555"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "X_train = np.concatenate((feature_train_vector[0:2,:],feature_train_vector[5:10,:]),axis=0).T\n",
        "Y_train = np.concatenate((feature_test_vector[0:2,:],feature_test_vector[5:10,:]),axis=0).T\n",
        "\n",
        "\n",
        "clf_lgr = LogisticRegression(C=1,random_state=0,solver='liblinear',max_iter=200)\n",
        "clf_lgr.fit(X_train, feature_train_vector[14,:].T)\n",
        "clf_lgr.predict(Y_train)\n",
        "print(clf_lgr.score(X_train, feature_train_vector[14,:].T))\n",
        "\n",
        "pred = clf_lgr.predict(Y_train)\n",
        "print(accuracy_score(feature_test_vector[14,:].T,pred,True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.29077048180524495\n",
            "0.3004959333465582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDnPKFIK_L13",
        "outputId": "fee0ba8f-91d5-4171-c1c8-255dcecf04ae"
      },
      "source": [
        "print(\"CPU: \\n\")\n",
        "\n",
        "Y_test = np.concatenate((feature_test_vector[3:4,:],feature_test_vector[6:7,:],feature_test_vector[1:2,:]),axis=0)\n",
        "\n",
        "accuracy_list = []\n",
        "\n",
        "for k in test_nframes:\n",
        "  i = 0\n",
        "  for j in k:\n",
        "    pred = clf_lgr.predict(Y_train[i:i+j,:])\n",
        "    acc = accuracy_score(feature_test_vector[14,i:i+j].T,pred,True)\n",
        "    #acc = clf_lgr.score(feature_test_vector[0:8,i:i+j].T,feature_test_vector[8,i:i+j])\n",
        "    accuracy_list.append(acc)\n",
        "    #print(acc)\n",
        "    i = i + j\n",
        "  \n",
        "print(\"Mean CPU accuracy: \", np.mean(accuracy_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU: \n",
            "\n",
            "Mean CPU accuracy:  0.5884674780428626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T0JSpSjZoZU",
        "outputId": "a37e35cd-20ae-4016-9751-e58173b04121"
      },
      "source": [
        "print(\"CPU: \\n\")\n",
        "\n",
        "accuracy_list = []\n",
        "\n",
        "for k in train_nframes:\n",
        "  i = 0\n",
        "  for j in k:\n",
        "    pred = clf_lgr.predict(feature_train_vector[0:12,i:i+j].T)\n",
        "    acc = accuracy_score(feature_train_vector[12,i:i+j].T,pred,True)\n",
        "    #acc = clf_lgr.score(feature_test_vector[0:12,i:i+j].T,feature_test_vector[12,i:i+j])\n",
        "    accuracy_list.append(acc)\n",
        "    #print(acc)\n",
        "    i = i + j\n",
        "  \n",
        "print(\"Mean CPU accuracy: \", np.mean(accuracy_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU: \n",
            "\n",
            "Mean CPU accuracy:  0.6403572724437385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA8NRahX_6IV",
        "outputId": "1848e3af-ed5e-4444-ca35-e997b6371ca5"
      },
      "source": [
        "print(\"CPU: \\n\")\n",
        "\n",
        "accuracy_list = []\n",
        "\n",
        "for k in test_nframes:\n",
        "  i = 0\n",
        "  for j in k:\n",
        "    pred = clf_lgr.predict(feature_test_norm[i:i+j,])\n",
        "    acc = accuracy_score(feature_test_vector[12,i:i+j].T,pred,True)\n",
        "    #acc = clf_lgr.score(feature_test_norm,feature_test_vector[12,i:i+j])\n",
        "    accuracy_list.append(acc)\n",
        "    #print(acc)\n",
        "    i = i + j\n",
        "  \n",
        "print(\"Mean CPU accuracy: \", np.mean(accuracy_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU: \n",
            "\n",
            "Mean CPU accuracy:  0.5776524845968057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz_t-PJIKn3Q"
      },
      "source": [
        "def spectrogram(wav,n_fft=256,hop_length=128,window='hamming'):\n",
        "    D = librosa.stft(wav, n_fft, hop_length, window='hamming')\n",
        "    spect, _ = librosa.magphase(D, power=1)\n",
        "    return spect\n",
        "\n",
        "spec = spectrogram(wav,256)\n",
        "\n",
        "print('Spectrogram shape', spec.shape)\n",
        "print('{min %.2f} {mean %.2f} {max %.2f}' % (np.amin(spec), np.mean(spec), np.amax(spec)))\n",
        "plt.plot(wav)\n",
        "plt.show()\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(spec, origin='lower')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(spec)\n",
        "plt.show()\n",
        "\n",
        "log_spec = librosa.power_to_db(spec ** 2, ref=np.min)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(log_spec, origin='lower',vmin=-60)\n",
        "plt.show()\n",
        "plt.hist(log_spec)\n",
        "plt.xlabel('Magnitude (dB)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-knjMiVIgtKm"
      },
      "source": [
        "print(n_fft)\n",
        "print(hop)\n",
        "x_train_sp = []\n",
        "train_labels = []\n",
        "k = 0\n",
        "for i in train_wav:\n",
        "  for j in i:\n",
        "    mel_sp = librosa.feature.melspectrogram(j, sr=fs, n_fft=2048, hop_length=1024, n_mels=64, power=1.0, fmin=10., fmax=4000.)\n",
        "    pad_width = 64 - mel_sp.shape[1]\n",
        "    mel_sp = librosa.amplitude_to_db(mel_sp)\n",
        "    if (pad_width > 0):\n",
        "      mel_sp = np.pad(mel_sp, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    mel_sp = mel_sp[:,0:64]\n",
        "    print(mel_sp.shape)\n",
        "    x_train_sp.append(mel_sp)\n",
        "    train_labels.append(k)\n",
        "  k = k + 1\n",
        "\n",
        "k = 0\n",
        "x_test_sp = []\n",
        "test_labels = []\n",
        "for i in test_wav:\n",
        "  for j in i:\n",
        "    mel_sp = librosa.feature.melspectrogram(j, sr=fs, n_fft=2048, hop_length=512, n_mels=64, power=1.0, fmin=10., fmax=4000.)\n",
        "    pad_width = 64 - mel_sp.shape[1]\n",
        "    mel_sp = librosa.amplitude_to_db(mel_sp)\n",
        "    if (pad_width > 0):\n",
        "      mel_sp = np.pad(mel_sp, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    mel_sp = mel_sp[:,0:64]\n",
        "    x_test_sp.append(mel_sp)\n",
        "    test_labels.append(k)\n",
        "  k = k + 1\n",
        "\n",
        "\n",
        "x_train = np.asarray(x_train_sp)\n",
        "x_test = np.asarray(x_test_sp)\n",
        "\n",
        "#display(Audio(train_wav[0][0],fs))\n",
        "#display(Audio(x_train_sp[0][0],fs))\n",
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha2OiYIaqlB6",
        "outputId": "6e1620c3-8d8e-40da-ea78-ef71792dd8b4"
      },
      "source": [
        "mel_sp_npar.shape[1:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(804, 804)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SVRlonLckbD8",
        "outputId": "f7806335-9ad4-4823-8e92-3bfc5186dc85"
      },
      "source": [
        "import sklearn.preprocessing\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import *\n",
        "\n",
        "\n",
        "\n",
        "# define model\n",
        "n_frames = x_train.shape[1]\n",
        "n_features = x_train.shape[2]\n",
        "num_classes = 5\n",
        "\n",
        "\n",
        "mlp = keras.Sequential() \n",
        "mlp.add(Flatten(input_shape=x_train.shape[1:]))\n",
        "mlp.add(Dense(num_classes+(n_frames*n_features)//2, activation='relu'))\n",
        "mlp.add(Dense(num_classes+(n_frames*n_features)//2, activation='relu'))\n",
        "mlp.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "mlp.summary()\n",
        "\n",
        "# model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = mlp.fit(x=x_train, y=keras.utils.to_categorical(train_labels), batch_size=64, epochs=30, verbose=2, validation_split=0.3)\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "print(history.history.keys())\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "loss, acc = mlp.evaluate(x_test, keras.utils.to_categorical(test_labels))\n",
        "print('Evaluation accuray', acc,'loss:', loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_22 (Flatten)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 2053)              8411141   \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 2053)              4216862   \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 5)                 10270     \n",
            "=================================================================\n",
            "Total params: 12,638,273\n",
            "Trainable params: 12,638,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "6/6 - 0s - loss: 671.1204 - accuracy: 0.2327 - val_loss: 1211.6531 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "6/6 - 0s - loss: 149.2153 - accuracy: 0.3241 - val_loss: 279.6701 - val_accuracy: 0.3290\n",
            "Epoch 3/30\n",
            "6/6 - 0s - loss: 36.1162 - accuracy: 0.3130 - val_loss: 198.2253 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "6/6 - 0s - loss: 15.6466 - accuracy: 0.3850 - val_loss: 70.5166 - val_accuracy: 0.1806\n",
            "Epoch 5/30\n",
            "6/6 - 0s - loss: 6.5425 - accuracy: 0.3823 - val_loss: 34.5226 - val_accuracy: 0.0194\n",
            "Epoch 6/30\n",
            "6/6 - 0s - loss: 2.0954 - accuracy: 0.4266 - val_loss: 17.3615 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "6/6 - 0s - loss: 1.0445 - accuracy: 0.5789 - val_loss: 10.6798 - val_accuracy: 0.1742\n",
            "Epoch 8/30\n",
            "6/6 - 0s - loss: 0.9107 - accuracy: 0.5873 - val_loss: 11.8285 - val_accuracy: 0.0194\n",
            "Epoch 9/30\n",
            "6/6 - 0s - loss: 0.8611 - accuracy: 0.6094 - val_loss: 11.6542 - val_accuracy: 0.0194\n",
            "Epoch 10/30\n",
            "6/6 - 0s - loss: 0.7957 - accuracy: 0.6454 - val_loss: 13.2405 - val_accuracy: 0.0323\n",
            "Epoch 11/30\n",
            "6/6 - 0s - loss: 0.7313 - accuracy: 0.6953 - val_loss: 15.1804 - val_accuracy: 0.0710\n",
            "Epoch 12/30\n",
            "6/6 - 0s - loss: 0.6365 - accuracy: 0.7230 - val_loss: 14.4756 - val_accuracy: 0.0710\n",
            "Epoch 13/30\n",
            "6/6 - 0s - loss: 0.6106 - accuracy: 0.7368 - val_loss: 17.1473 - val_accuracy: 0.1032\n",
            "Epoch 14/30\n",
            "6/6 - 0s - loss: 0.5101 - accuracy: 0.7950 - val_loss: 19.2254 - val_accuracy: 0.0774\n",
            "Epoch 15/30\n",
            "6/6 - 0s - loss: 0.4889 - accuracy: 0.7922 - val_loss: 18.8338 - val_accuracy: 0.1290\n",
            "Epoch 16/30\n",
            "6/6 - 0s - loss: 0.4203 - accuracy: 0.8393 - val_loss: 17.8953 - val_accuracy: 0.0645\n",
            "Epoch 17/30\n",
            "6/6 - 0s - loss: 0.3249 - accuracy: 0.9058 - val_loss: 21.0148 - val_accuracy: 0.0774\n",
            "Epoch 18/30\n",
            "6/6 - 0s - loss: 0.2923 - accuracy: 0.8947 - val_loss: 24.9438 - val_accuracy: 0.0387\n",
            "Epoch 19/30\n",
            "6/6 - 0s - loss: 0.2785 - accuracy: 0.9030 - val_loss: 20.5020 - val_accuracy: 0.0387\n",
            "Epoch 20/30\n",
            "6/6 - 0s - loss: 0.2932 - accuracy: 0.8809 - val_loss: 21.5946 - val_accuracy: 0.0516\n",
            "Epoch 21/30\n",
            "6/6 - 0s - loss: 0.1912 - accuracy: 0.9391 - val_loss: 21.8627 - val_accuracy: 0.0903\n",
            "Epoch 22/30\n",
            "6/6 - 0s - loss: 0.1696 - accuracy: 0.9418 - val_loss: 23.6391 - val_accuracy: 0.1032\n",
            "Epoch 23/30\n",
            "6/6 - 0s - loss: 0.1399 - accuracy: 0.9612 - val_loss: 25.3885 - val_accuracy: 0.1097\n",
            "Epoch 24/30\n",
            "6/6 - 0s - loss: 0.1347 - accuracy: 0.9557 - val_loss: 20.7585 - val_accuracy: 0.1548\n",
            "Epoch 25/30\n",
            "6/6 - 0s - loss: 0.1211 - accuracy: 0.9529 - val_loss: 23.1820 - val_accuracy: 0.0903\n",
            "Epoch 26/30\n",
            "6/6 - 0s - loss: 0.0814 - accuracy: 0.9834 - val_loss: 25.1484 - val_accuracy: 0.0452\n",
            "Epoch 27/30\n",
            "6/6 - 0s - loss: 0.0533 - accuracy: 0.9889 - val_loss: 25.1913 - val_accuracy: 0.1097\n",
            "Epoch 28/30\n",
            "6/6 - 0s - loss: 0.0306 - accuracy: 1.0000 - val_loss: 25.8526 - val_accuracy: 0.0839\n",
            "Epoch 29/30\n",
            "6/6 - 0s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 25.5988 - val_accuracy: 0.1355\n",
            "Epoch 30/30\n",
            "6/6 - 0s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 25.8425 - val_accuracy: 0.0774\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 11.0038 - accuracy: 0.3409\n",
            "Evaluation accuray 0.34090909361839294 loss: 11.003780364990234\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}